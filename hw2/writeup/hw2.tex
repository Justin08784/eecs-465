\documentclass[a4paper,10pt]{article}
\usepackage[utf8]{inputenc}
\newcommand{\myparagraph}[1]{\paragraph{#1}\mbox{}\\}
\usepackage[a4paper,margin=3.5cm]{geometry} %sets the page geometry
\usepackage{url}
\usepackage{dirtytalk}
\usepackage{graphicx} % package for \includegraphics
\usepackage{wrapfig} % figure wrapping
\setlength{\parskip}{1em} % set space when paragraphs are used
\setlength{\parindent}{0pt}
\usepackage{amssymb}
\usepackage{amsmath}
\usepackage{amsthm}
\usepackage{tcolorbox}
\usepackage{mathtools}

% lets you use \blankpage to make a blank page
\newcommand{\blankpage}{
\newpage
\thispagestyle{empty}
\mbox{}
\newpage
}

% self explanatory
\theoremstyle{definition}
\newtheorem{theorem}{theorem}[section]
\newtheorem{definition}{definition}[section]
\newtheorem{corollary}{corollary}[theorem]
\newtheorem{lemma}[theorem]{lemma}


% other
\DeclarePairedDelimiter\floor{\lfloor}{\rfloor} %floor function

\begin{document}
\textbf{1. (5 points) Is a single point convex? Use the definition of convexity to justify your answer.}

Yes, a singleton is a convex set.

\begin{proof} 
Recall that a set $S \subseteq \mathbb{R}^n$ is convex \textit{iff}
$x, y \in S, \theta \in [0, 1] \implies \theta x + (1 - \theta) y \in S$

Consider the singleton $\{a\}\subseteq\mathbb{R}^n$. Fix $x, y \in \{a\}, \theta \in [0,1]$.

ETS $\theta x + (1 - \theta) y \in \{a\}$

Since $a$ is the only element of $\{a\}$, $x = y = a$.

Thus, $\theta x + (1 - \theta) y = \theta a + (1 - \theta) a = a \in \{a\}$
\end{proof} 

\bigskip
\textbf{2. (10 points) Is the function...}

Yes, the function is convex.

\begin{proof}

$f(x) = \lvert 2 - 5x\rvert + 2x + 8e^{-4x} - 1$

Define:

$f_1(x) \coloneq 2 - 5x$ (affine)

$f_2(x) \coloneq \lvert x \rvert$ (absolute value)

$f_3(x) \coloneq 2x$ (affine)

$f_4(x) \coloneq e^{-4x}$ (exponential)

$f_5(x) \coloneq - 1$ (affine)

These are all convex functions according to slide 31 of the "Convexity and Optimization" lecture on 09/09.

$f = f_2 \circ f_1 + f_3 + 8f_4 + f_5$

(1) $f_1 \text{ is affine } \land f_2 \text{ is convex} \implies f_2 \circ f_1 \text{ is convex}$
% (composing affine map with convex function is convex)

(2) $8 \geq 0 \land f_4 \text{ is convex} \implies 8f_4 \text{ is convex}$
% (non-negative scalar multiplication preserves convexity)

Thus, $f$ is a sum of convex functions.
Since summation preserves convexity, $f$ is convex.
\end{proof}


\bigskip
\textbf{3. (10 points) Rewrite the following optimization problem...}

\[
\begin{aligned}
    \text{minimize}_{x} \quad & -3x_1 + 4x_2 + 3 \\
    \text{subject to} \quad & x_2 + 3 \leq 0, \\
                            & 2x_1 - 5x_2 + 2 \leq 0, \\
                            & -x_2 + 5 \leq 0, \\
                            & x_1 - x_2 - 6.3 = 0.
\end{aligned}
\]

\bigskip
\textbf{4. (15 points) Consider...}

$\delta f$ contains more than 1 value only at $\{-\frac{1}{3}, 1\}$

$\delta f(-\frac{1}{3}) = [-2, 2]$

$\delta f(1) = [2, 6]$

\begin{proof}

$f = max\{g, h\} \text{ where } g(x) \coloneq 3x^2 - 2, h(x) \coloneq 2x - 1$

$g'(x) = 6x$

$h'(x) = 2$

$g,h$ are convex and pointwise maximum preserves convexity

$\implies f$ is convex

$\implies \delta f \neq \varnothing$ everywhere.

Line $h$ makes two intersections with $g$:

$g = h \iff 3x^2 - 2 = 2x - 1 \iff (3x + 1)(x - 1) = 0 \iff x \in \{-\frac{1}{3}, 1\}$

Due to strict convexity of $g$, \textbf{(A)} $g < h$ on $(-\frac{1}{3}, 1)$ and $h < g$ everywhere else.

$g, h$ differentiable everywhere $\land \textbf{ (A)}$

$\implies f$ is differentiable on $\mathbb{R} \setminus \{-\frac{1}{3}, 1\}$

$\implies \forall x \in \mathbb{R} \setminus \{-\frac{1}{3}, 1\}, \delta f(x) = \{f'(x)\} \text{ (a singleton)}$

Thus, $\delta f$ can contain multiple elements only on $\{-\frac{1}{3}, 1\}$.

$\textbf{(1) } g'(-\frac{1}{3}) = -2 \neq 2 = h'(-\frac{1}{3})$

$\textbf{(2) } g'(1) = 6 \neq 2 = h'(1)$

\textbf{(1), (2)} imply that $f$ has non-differentiable kinks at $-\frac{1}{3}$ and $1$.

Thus, on $\{-\frac{1}{3}, 1\}, \delta f = [\min\{g', h'\},\max\{g', h'\}]$.

$\delta f(-\frac{1}{3}) = [-2, 2]$

$\delta f(1) = [2, 6]$

\end{proof}


\bigskip
\textbf{5. A linear program...}

We assume that:
$x \in \mathbb{R}^n, h \in \mathbb{R}^m, b \in \mathbb{R}^p$

Thus, $c \in \mathbb{R}^{n \times 1}$, $G = (G_{ij}) \in \mathbb{R}^{m \times n}$, $A = (A_{ij}) \in \mathbb{R}^{p \times n}$

\textbf{a. (10 points) Write down...}

\[
    g:\mathbb{R}^m \times \mathbb{R}^p, \\
    g(\lambda, \nu) = \inf\{
        c^Tx + \lambda^{T}(Gx - h) + \nu^{T}(Ax - b)
        \mid x\in\mathbb{R}^n
    \}
\]

\textbf{b. (5 points) Write down...}

\[
\begin{aligned}
    \text{maximize}_{\lambda, \nu} \quad & g(\lambda, \nu) \\
    \text{subject to} \quad & \lambda \succeq 0
\end{aligned}
\]


\textbf{c. (5 points) Suppose you solved...}

$d^* = p^*$

Note: this needs justification. Something about prime duality theorem.



\textbf{Software 3. }

\textbf{a. (5 points) Write down...}

Suppose that the primal problem is:
\[
\begin{aligned}
    \text{minimize}_{x} \quad & f_0(x) \\
    \text{subject to} \quad & f_i(x) \leq 0 \quad & 1 \leq i \leq m\\
                            & h_i(x) = 0    \quad & 1 \leq i \leq p 
\end{aligned}
\]

Then the barrier method reformulation is: 
\[
\begin{aligned}
    \text{minimize}_{x} \quad & tf_0(x) + \phi(x)\\
    \text{subject to} \quad & h_i(x) = 0 \quad & 1 \leq i \leq p\\
\end{aligned}
\]

\[
\begin{aligned}
    \phi & : \mathcal{D} \rightarrow \mathbb{R}, \text{ where }\\
    \mathcal{D} & \coloneq \{x \in \mathbb{R} ^ n \mid \forall 1\leq i\leq m, f_i(x) < 0\}\\
    \forall & x \in \mathcal{D}, \phi(x) \coloneq \sum_{i=1}^{m} -log(-f_i(x))
\end{aligned}
\]

$x \mapsto tf_0(x) + \phi(x)$ is the new objective function,
with optimization variable $x$ and objective-barrier weight $t$.

\textbf{b. (5 points) Write down...}


Suppose that the primal problem is:
\[
\begin{aligned}
    & \text{minimize}_{x} \quad & c^Tx \\
    & \text{subject to} \quad & Gx \preceq h \\
    & \quad & Ax = b  
\end{aligned}
\]

...where:

$x \in \mathbb{R}^n, h \in \mathbb{R}^m, b \in \mathbb{R}^p$

$c \in \mathbb{R}^{n \times 1}$, $G = (G_{ij}) \in \mathbb{R}^{m \times n}$, $A = (A_{ij}) \in \mathbb{R}^{p \times n}$

Then the barrier method reformulation is: 
\[
\begin{aligned}
    \text{minimize}_{x} \quad & tc^Tx + \phi(x)\\
    \text{subject to} \quad & Ax = b \quad & 1 \leq i \leq p\\
\end{aligned}
\]

\[
\begin{aligned}
    \phi & : \mathcal{D} \rightarrow \mathbb{R}, \text{ where }\\
    \mathcal{D} & \coloneq \{x \in \mathbb{R} ^ n \mid \forall 1\leq i\leq m, G_i^Tx - h_i < 0\}\\
    \forall & x \in \mathcal{D}, \phi(x) \coloneq \sum_{i=1}^{m} -log(-(G_i^Tx - h_i))
\end{aligned}
\]

$x \mapsto tc^Tx + \phi(x)$ is the new objective function,
with optimization variable $x$ and objective-barrier weight $t$.

\end{document}

